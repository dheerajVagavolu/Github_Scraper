{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "repo_list = open('list').readlines()\n",
    "print(len(repo_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://github.com/airbnb/epoxy/', '2', '1')]\n"
     ]
    }
   ],
   "source": [
    "# Name # Issues # Pulls\n",
    "range_list = [(i.split(' ')[0], i.split(' ')[1], i.split(' ')[2]) for i in repo_list]\n",
    "print(range_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# website urls\n",
    "# base_url = \"https://github.com/airbnb/epoxy/pulls?q=is%3Apr+is%3Aclosed+closed%3A2019-10-30..2020-04-30\"\n",
    "\n",
    "def load_base(base_url):\n",
    "    print(base_url)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.get(base_url)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "\n",
    "    issues = soup.find_all('div', class_=\"flex-auto min-width-0 lh-condensed p-2 pr-3 pr-md-2\")\n",
    "    print(len(issues))\n",
    "    return [issues, soup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num(string):\n",
    "    return string.strip().split(' ')[0].replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deeper(kind, href, close_date, soup):\n",
    "    \n",
    "    print()\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(href)\n",
    "    driver.implicitly_wait(5)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "    \n",
    "    participants = soup.find('div', class_=\"participation\")\n",
    "    participants = get_num(participants.text.strip())\n",
    "    \n",
    "    title = soup.find('span', class_=\"js-issue-title\")\n",
    "    title = title.text.strip()\n",
    "    \n",
    "    labels = soup.find('div', class_=\"labels\")\n",
    "    labels = labels.text.strip()\n",
    "    \n",
    "    status = soup.find('span', class_=\"State\")\n",
    "    status = status['title'].strip()\n",
    "    status = status.split(' ')[-1]\n",
    "    \n",
    "    ## Prints\n",
    "    \n",
    "    print(kind,\"\\n---------\")\n",
    "    print(\"Title:\",title)\n",
    "    print(\"Status:\",status)\n",
    "    print(\"Labels:\",labels)\n",
    "    print(\"Participants:\",participants)\n",
    "    \n",
    "    \n",
    "    ## Files\n",
    "    \n",
    "    if kind == \"pull\":\n",
    "        \n",
    "        try:\n",
    "            file_changed = soup.find(id=\"files_tab_counter\")\n",
    "            file_changed = file_changed.text.strip()\n",
    "        except:\n",
    "            file_changed = 'n/a'\n",
    "        \n",
    "        try:\n",
    "            lines_added = soup.find('span', class_=\"text-green\")\n",
    "            lines_added = lines_added.text.strip()\n",
    "            lines_added = lines_added[1:]\n",
    "        except:\n",
    "            lines_added = 'n/a'\n",
    "        \n",
    "        try:\n",
    "            lines_removed = soup.find('span', class_=\"text-red\")\n",
    "            lines_removed = lines_removed.text.strip()\n",
    "            lines_removed = lines_removed[1:]\n",
    "        except:\n",
    "            lines_removed = 'n/a'\n",
    "\n",
    "        print(\"Files Changed:\",file_changed)\n",
    "        print(\"Lines Added:\",lines_added)\n",
    "        print(\"Lines Removed\",lines_removed)\n",
    "        print(\"Approved Date:\",close_date)\n",
    "        \n",
    "        object_tuple = [title, labels, \\\n",
    "                        participants,\\\n",
    "                        close_date, \\\n",
    "                        file_changed, lines_added, lines_removed,\\\n",
    "                        status]\n",
    "        \n",
    "        print(object_tuple)\n",
    "    \n",
    "    if kind ==\"issue\":\n",
    "        \n",
    "        try:\n",
    "            comment_tab = soup.find('div',\"TableObject-item TableObject-item--primary\")\n",
    "        except:\n",
    "            comment_tab = 'n/a'\n",
    "        \n",
    "        try:\n",
    "            rel_time = soup.find('relative-time')\n",
    "            open_date = rel_time['datetime']\n",
    "            open_date = open_date[:10]\n",
    "        except:\n",
    "            open_date = 'n/a'\n",
    "            \n",
    "        \n",
    "        print(\"Inner_date:\",open_date)\n",
    "        print(\"Outer_date:\",close_date)\n",
    "        \n",
    "        try:\n",
    "            comments = comment_tab.text.strip().split('\\n')[-1].split(' ')[1].strip()\n",
    "        except:\n",
    "            comments = 'n/a'\n",
    "            \n",
    "        print(\"Comments:\", comments)\n",
    "          \n",
    "        object_tuple = [title, labels, \\\n",
    "                        participants, open_date,\\\n",
    "                        close_date, \\\n",
    "                        comments,\\\n",
    "                        status]\n",
    "        \n",
    "        print(object_tuple)\n",
    "    \n",
    "    return object_tuple\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def outer_page(issues, soup):\n",
    "    objects = []\n",
    "    for issue in issues:\n",
    "            meta_data = issue.find('relative-time')\n",
    "            issue_link = issue.find_all('a', class_='link-gray-dark v-align-middle no-underline h4 js-navigation-open')\n",
    "            close_date = meta_data['datetime'][:10]\n",
    "            for link in issue_link:\n",
    "                try:\n",
    "                    if 'issue' in link['id']:\n",
    "                        href = link['href']\n",
    "                        \n",
    "                        kind = \"pull\"\n",
    "                        if \"issue\" in href:\n",
    "                            kind = \"issue\"\n",
    "                        \n",
    "                        href = 'https://github.com'+href\n",
    "                        print(\"\\n\",href) \n",
    "                        obj = get_deeper(kind, href, close_date, soup)\n",
    "                        objects.append(obj)\n",
    "                except:\n",
    "                    pass\n",
    "    return objects\n",
    "\n",
    "# outer_page()\n",
    "# outer_page(\"pull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(string):\n",
    "    return string.split('/')[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base_Url: https://github.com/airbnb/epoxy/\n",
      "Issues Pages: 2\n",
      "https://github.com/airbnb/epoxy/issues?page=1&q=is%3Aissue+is%3Aclosed+closed%3A2019-10-30..2020-04-30\n",
      "25\n",
      "\n",
      " https://github.com/airbnb/epoxy/issues/949\n",
      "\n",
      "issue \n",
      "---------\n",
      "Title: Incremental kapt\n",
      "Status: Closed\n",
      "Labels: None yet\n",
      "Participants: 2\n",
      "Inner_date: 2020-04-23\n",
      "Outer_date: 2020-04-23\n",
      "Comments: 2\n",
      "['Incremental kapt', 'None yet', '2', '2020-04-23', '2020-04-23', '2', 'Closed']\n",
      "https://github.com/airbnb/epoxy/issues?page=2&q=is%3Aissue+is%3Aclosed+closed%3A2019-10-30..2020-04-30\n",
      "22\n",
      "\n",
      " https://github.com/airbnb/epoxy/issues/890\n",
      "\n",
      "issue \n",
      "---------\n",
      "Title: Use multiple layout per one model?\n",
      "Status: Closed\n",
      "Labels: None yet\n",
      "Participants: 2\n",
      "Inner_date: 2019-12-11\n",
      "Outer_date: 2019-12-12\n",
      "Comments: 2\n",
      "['Use multiple layout per one model?', 'None yet', '2', '2019-12-11', '2019-12-12', '2', 'Closed']\n",
      "Pulls Pages: 1\n",
      "https://github.com/airbnb/epoxy/pulls?page=1&q=is%3Apr+is%3Aclosed+closed%3A2019-10-30..2020-04-30\n",
      "13\n",
      "\n",
      " https://github.com/airbnb/epoxy/pull/929\n",
      "\n",
      "pull \n",
      "---------\n",
      "Title: Travis CI build status of master\n",
      "Status: Merged\n",
      "Labels: None yet\n",
      "Participants: 2\n",
      "Files Changed: 1\n",
      "Lines Added: 3\n",
      "Lines Removed 0\n",
      "Approved Date: 2020-03-20\n",
      "['Travis CI build status of master', 'None yet', '2', '2020-03-20', '1', '3', '0', 'Merged']\n"
     ]
    }
   ],
   "source": [
    "for i in range_list:\n",
    "    base_url = i[0]\n",
    "    name = get_name(base_url)\n",
    "    print(\"Base_Url:\", base_url)\n",
    "    num_pages_issues = int(i[1])\n",
    "    num_pages_pulls = int(i[2])\n",
    "    \n",
    "    print(\"Issues Pages:\",num_pages_issues)\n",
    "    \n",
    "    dat = ['Title', 'Labels', 'Participants', 'Open_date', 'Close_date', 'Comments', 'Status']\n",
    "    \n",
    "    with open('data/'+name+'_'+\"issues_2019-10-30_2020-04-30\" + '.csv', 'a', newline='') as csvfile:\n",
    "            f1w = csv.writer(csvfile)\n",
    "            f1w.writerow(dat)\n",
    "            \n",
    "                \n",
    "    for num in range(num_pages_issues):\n",
    "        link = \"issues?page=\"+str(num+1)+\"&q=is%3Aissue+is%3Aclosed+closed%3A2019-10-30..2020-04-30\"\n",
    "        link = base_url + link\n",
    "        returns = load_base(link)\n",
    "        time.sleep(5)\n",
    "        objects = outer_page(returns[0], returns[1])\n",
    "        with open('data/'+name+'_'+\"issues_2019-10-30_2020-04-30\" + '.csv', 'a', newline='') as csvfile:\n",
    "            f1w = csv.writer(csvfile)\n",
    "            for _obj in objects:\n",
    "                f1w.writerow(_obj)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    print(\"Pulls Pages:\",num_pages_pulls)\n",
    "    \n",
    "    dat = ['Title', 'Labels', 'Participants', 'Approved_date', 'files_changed', 'lines_added','lines_deleted','Status']\n",
    "    \n",
    "    with open('data/'+name+'_'+\"pulls_2019-10-30_2020-04-30\" + '.csv', 'a', newline='') as csvfile:\n",
    "            f1w = csv.writer(csvfile)\n",
    "            f1w.writerow(dat)\n",
    "    \n",
    "    for num in range(num_pages_pulls):\n",
    "        link = \"pulls?page=\"+str(num+1)+\"&q=is%3Apr+is%3Aclosed+closed%3A2019-10-30..2020-04-30\"\n",
    "        link = base_url + link\n",
    "        returns = load_base(link)\n",
    "        time.sleep(5)\n",
    "        objects = outer_page(returns[0], returns[1])\n",
    "        with open('data/'+name+'_'+\"pulls_2019-10-30_2020-04-30\" + '.csv', 'a', newline='') as csvfile:\n",
    "            f1w = csv.writer(csvfile)\n",
    "            for _obj in objects:\n",
    "                f1w.writerow(_obj)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
